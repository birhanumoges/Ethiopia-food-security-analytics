{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdysHZS4QzpN"
      },
      "source": [
        "# Ethiopian food security Classification Notebook\n",
        "This notebook loads data and prepares a Ethiopian food security\n",
        "classification workflow."
      ],
      "id": "HdysHZS4QzpN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJMlwmhIQzpP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "print('Notebook loaded successfully')"
      ],
      "id": "FJMlwmhIQzpP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XLmLJQnQzpP"
      },
      "outputs": [],
      "source": [
        "# Load CSV file\n",
        "df = pd.read_csv(r\"C:/Users/DELL/Documents/NLP/wfp_food_prices_eth.csv\")\n",
        "\n",
        "# View first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Access a column\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ],
      "id": "9XLmLJQnQzpP"
    },
    {
      "cell_type": "code",
      "source": [
        "# remove metadata row\n",
        "df = df[df['date'] != '#date']\n",
        "\n",
        "# convert date column\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# convert numeric columns\n",
        "df['price'] = pd.to_numeric(df['price'])\n",
        "df['usdprice'] = pd.to_numeric(df['usdprice'])"
      ],
      "metadata": {
        "id": "T_unMagHRbfB"
      },
      "id": "T_unMagHRbfB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' regional distribution:{df['admin1'].value_counts()}')\n",
        "df['commodity'].value_counts()"
      ],
      "metadata": {
        "id": "7NSS1QnwRlsF"
      },
      "id": "7NSS1QnwRlsF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# COMPLETE DATA CLEANING AND NLP PREPARATION PIPELINE\n",
        "# =============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Remove Duplicates\n",
        "# -----------------------------\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ Check Missing Values\n",
        "# -----------------------------\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_values)\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ Clean & Normalize Text Columns\n",
        "# -----------------------------\n",
        "text_cols = ['commodity', 'category', 'market', 'admin1', 'admin2', 'unit']\n",
        "\n",
        "for col in text_cols:\n",
        "    df[col] = df[col].astype(str)  # ensure string type\n",
        "    df[col] = df[col].str.lower().str.strip()  # lowercase and strip spaces\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Remove Special Characters from Commodity Names\n",
        "# -----------------------------\n",
        "df['commodity_clean'] = df['commodity'].apply(lambda x: re.sub(r'[^a-zA-Z ]', '', x))\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ Tokenize Commodity Names\n",
        "# -----------------------------\n",
        "df['tokens'] = df['commodity_clean'].str.split()\n",
        "\n",
        "# -----------------------------\n",
        "# 7Ô∏è‚É£ Word Frequency Analysis (Top 10 words in commodities)\n",
        "# -----------------------------\n",
        "all_words = Counter(word for tokens in df['tokens'] for word in tokens)\n",
        "print(\"Top 10 words in commodity names:\\n\", all_words.most_common(10))\n",
        "\n",
        "# -----------------------------\n",
        "# AUTOMATIC STANDARDIZATION USING RULES\n",
        "# -----------------------------\n",
        "\n",
        "# Convert to lowercase and remove special characters first\n",
        "df['commodity_clean'] = df['commodity'].str.lower().str.strip()\n",
        "df['commodity_clean'] = df['commodity_clean'].apply(lambda x: re.sub(r'[^a-zA-Z ]', '', x))\n",
        "\n",
        "# Create an empty column for standardized commodities\n",
        "df['commodity_standard'] = ''\n",
        "\n",
        "# Define simple rules using for loop\n",
        "for i, row in df.iterrows():\n",
        "    name = row['commodity_clean']\n",
        "\n",
        "    # cereals\n",
        "    if 'maize' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'maize'\n",
        "    elif 'sorghum' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'sorghum'\n",
        "    elif 'teff' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'teff'\n",
        "    elif 'wheat' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'wheat'\n",
        "\n",
        "    # livestock\n",
        "    elif 'goat' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'goat'\n",
        "    elif 'sheep' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'sheep'\n",
        "\n",
        "    # other foods\n",
        "    elif 'butter' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'butter'\n",
        "    elif 'beans' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'beans'\n",
        "    elif 'potatoes' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'potatoes'\n",
        "    elif 'kocho' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'kocho'\n",
        "    elif 'wage' in name:\n",
        "        df.at[i, 'commodity_standard'] = 'wage'\n",
        "\n",
        "    # If nothing matches, keep original\n",
        "    else:\n",
        "        df.at[i, 'commodity_standard'] = name\n",
        "\n",
        "# Check the result\n",
        "print(df[['commodity', 'commodity_clean', 'commodity_standard']].head(10))\n",
        "print(\"\\nStandardized commodity counts:\\n\", df['commodity_standard'].value_counts().head(10))\n",
        "\n",
        "# -----------------------------\n",
        "# 9Ô∏è‚É£ Commodity Counts\n",
        "# -----------------------------\n",
        "commodity_counts = df['commodity_standard'].value_counts()\n",
        "print(\"\\nTop Commodities:\\n\", commodity_counts.head(10))\n",
        "\n",
        "# -----------------------------\n",
        "# üîü Category Counts\n",
        "# -----------------------------\n",
        "category_counts = df['category'].value_counts()\n",
        "print(\"\\nCategory Distribution:\\n\", category_counts)\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Vectorize Commodity Names for NLP\n",
        "# -----------------------------\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_text = vectorizer.fit_transform(df['commodity_standard'])\n",
        "\n",
        "print(\"\\nTF-IDF vector shape:\", X_text.shape)\n",
        "print(\"Example feature names:\", vectorizer.get_feature_names_out()[:10])\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£2Ô∏è‚É£ Summary\n",
        "# -----------------------------\n",
        "print(\"Text columns cleaned, tokenized, and vectorized its ready for NLP analysis.\")"
      ],
      "metadata": {
        "id": "thQWKLacRrbD"
      },
      "id": "thQWKLacRrbD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEXT STAGE ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ===============================\n",
        "# 1Ô∏è‚É£ Commodity Demand Analysis\n",
        "# ===============================\n",
        "commodity_demand = df['commodity_standard'].value_counts()\n",
        "\n",
        "plt.figure()\n",
        "commodity_demand.head(10).plot(kind='bar')\n",
        "plt.title(\"Top 10 Most Demanded Commodities\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 2Ô∏è‚É£ Category Consumption Patterns\n",
        "# ===============================\n",
        "category_demand = df['category'].value_counts()\n",
        "\n",
        "plt.figure()\n",
        "category_demand.plot(kind='bar')\n",
        "plt.title(\"Demand by Food Category\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 3Ô∏è‚É£ Average Price by Commodity\n",
        "# ===============================\n",
        "\n",
        "# Most expensive commodities\n",
        "plt.figure()\n",
        "price_stats['mean'].sort_values().tail(10).plot(kind='bar')\n",
        "plt.title(\"Most Expensive Commodities\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Cheapest commodities\n",
        "plt.figure()\n",
        "price_stats['mean'].sort_values().head(10).plot(kind='bar')\n",
        "plt.title(\"Most Affordable Commodities\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# 4Ô∏è‚É£ PRICE VOLATILITY (FOOD RISK INDICATOR)\n",
        "# =========================================================\n",
        "\n",
        "volatility = df.groupby('commodity_standard')['price'].std().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n MOST VOLATILE (RISKY) FOODS:\\n\")\n",
        "print(volatility.head(10))\n",
        "\n",
        "plt.figure()\n",
        "volatility.head(10).plot(kind='bar')\n",
        "plt.title(\"Price Volatility Risk\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# 5Ô∏è‚É£ INFLATION / PRICE SPIKE DETECTION\n",
        "# =========================================================\n",
        "\n",
        "df['price_change'] = df.groupby('commodity_standard')['price'].pct_change()\n",
        "\n",
        "spikes = df[df['price_change'] > 0.30]\n",
        "\n",
        "print(\"\\n PRICE SPIKES (>30% increase):\")\n",
        "print(spikes[['commodity_standard','price_change']].head())\n",
        "\n",
        "# =========================================================\n",
        "# 6Ô∏è‚É£ FOOD SECURITY RISK INDEX\n",
        "# =========================================================\n",
        "\n",
        "# risk = high price + high volatility\n",
        "risk_df = pd.DataFrame({\n",
        "    'avg_price': df.groupby('commodity_standard')['price'].mean(),\n",
        "    'volatility': volatility\n",
        "})\n",
        "\n",
        "risk_df['risk_score'] = risk_df['avg_price'] * risk_df['volatility']\n",
        "risk_df = risk_df.sort_values('risk_score', ascending=False)\n",
        "\n",
        "print(\"\\n FOOD SECURITY RISK FOODS:\\n\")\n",
        "print(risk_df.head(10))\n",
        "\n",
        "# ===============================\n",
        "# 4Ô∏è‚É£ Seasonal Price Trends\n",
        "# ===============================\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['month'] = df['date'].dt.month\n",
        "\n",
        "monthly_price = df.groupby('month')['price'].mean()\n",
        "\n",
        "plt.figure()\n",
        "monthly_price.plot(marker='o')\n",
        "plt.title(\"Seasonal Price Trend\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Average Price\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 6Ô∏è‚É£ Market Distribution Analysis\n",
        "# ===============================\n",
        "market_counts = df['market'].value_counts().head(10)\n",
        "\n",
        "plt.figure()\n",
        "market_counts.plot(kind='bar')\n",
        "plt.title(\"Top Markets by Activity\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "category_price.plot(kind='bar')\n",
        "plt.title('Average Price by Category')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ===============================\n",
        "# 7Ô∏è‚É£ Food Price Volatility (Risk Indicator)\n",
        "# ===============================\n",
        "price_volatility = df.groupby('commodity_standard')['price'].std().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nMost Volatile Commodities:\\n\")\n",
        "print(price_volatility.head(10))\n",
        "\n",
        "# ===============================\n",
        "# 8Ô∏è‚É£ Insight Summary\n",
        "# ===============================\n",
        "print(\"\\nKEY INSIGHTS\")\n",
        "print(\"‚Ä¢ High demand commodities indicate staple foods.\")\n",
        "print(\"‚Ä¢ Category demand shows nutrition dependence.\")\n",
        "print(\"‚Ä¢ Seasonal peaks may indicate drought or shortages.\")\n",
        "print(\"‚Ä¢ Volatile prices signal food security risks.\")\n",
        "print(\"‚Ä¢ Clusters reveal similar food groups and substitutes.\")"
      ],
      "metadata": {
        "id": "9uf9z1K0RzQH"
      },
      "id": "9uf9z1K0RzQH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "num_clusters = 10\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "df['commodity_cluster'] = kmeans.fit_predict(X_text)\n",
        "\n",
        "score = silhouette_score(X_text, df['commodity_cluster'])\n",
        "print(\"Silhouette Score:\", score)\n",
        "\n",
        "df[['commodity_standard', 'commodity_cluster']].tail(15)"
      ],
      "metadata": {
        "id": "S0-niVE2R_o7"
      },
      "id": "S0-niVE2R_o7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_clusters):\n",
        "    print(f\"\\nCluster {i}:\")\n",
        "    print(df[df['commodity_cluster'] == i]['commodity_standard'].head(10).tolist())"
      ],
      "metadata": {
        "id": "e2GThkamSVjv"
      },
      "id": "e2GThkamSVjv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "cluster_words = []\n",
        "for i in range(num_clusters):\n",
        "    words = \" \".join(df[df['commodity_cluster']==i]['commodity_standard']).split()\n",
        "    common = Counter(words).most_common(5)\n",
        "    cluster_words.append([w for w,_ in common])\n",
        "\n",
        "pd.DataFrame(cluster_words, index=[f\"Cluster {i}\" for i in range(num_clusters)])"
      ],
      "metadata": {
        "id": "dt66Q3zMSaSF"
      },
      "id": "dt66Q3zMSaSF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "market_counts = df.groupby(['admin1','commodity_standard']).size().unstack(fill_value=0)\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.heatmap(market_counts, cmap='YlGnBu')\n",
        "plt.title('Commodity Distribution by Region')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6W4-l0UISfKD"
      },
      "id": "6W4-l0UISfKD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}